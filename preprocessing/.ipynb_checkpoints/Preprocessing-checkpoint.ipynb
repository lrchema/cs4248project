{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Yong Han Ching\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Yong Han\n",
      "[nltk_data]     Ching\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Yong Han\n",
      "[nltk_data]     Ching\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "STOPWORD = stopwords.words('english')\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/raw_data/fulltrain.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    17870\n",
      "1    14047\n",
      "4     9995\n",
      "2     6942\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(df[0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_to_morphy(pos_tag):\n",
    "    \"\"\"Convert POS tag to Morphy tag for Wordnet to recognise\"\"\"\n",
    "    tag_dict = {\"JJ\": wordnet.ADJ,\n",
    "                \"NN\": wordnet.NOUN,\n",
    "                \"VB\": wordnet.VERB,\n",
    "                \"RB\": wordnet.ADV}\n",
    "\n",
    "    # Return tag if found, Noun if not found\n",
    "    return tag_dict.get(pos_tag[:2], wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(document):\n",
    "#     print(document)\n",
    "    # Lowercasing all string elements\n",
    "    document = [doc.lower() for doc in document]\n",
    "    \n",
    "    # Basic tokenization\n",
    "    document = [re.sub(r'[\\|/|-]', r' ', doc) for doc in document]\n",
    "    \n",
    "    #print(document)\n",
    "    #         Stop word Removal\n",
    "    filtered_words = []\n",
    "    for doc in document:\n",
    "        lst = [word for word in doc.split() if word not in STOPWORD]\n",
    "        doc_string = ' '.join(lst)\n",
    "        filtered_words.append(doc_string)\n",
    "        \n",
    "    document = filtered_words\n",
    "    document = pd.Series(document)\n",
    "    \n",
    "    \n",
    "# #     # ONLY ONE OF STEMMING OR LEMMATIZATION\n",
    "# #     # Lemmatize to tokens after POS tagging -> Take very long?\n",
    "#     document = [\" \".join([lem.lemmatize(word.lower(), pos=pos_to_morphy(tag)) \n",
    "#                           for word, tag in pos_tag(TreebankWordTokenizer().tokenize(doc))]) for doc in document] \n",
    "    \n",
    "    document = [\" \".join([stem.stem(word.lower()) for word, tag in pos_tag(TreebankWordTokenizer().tokenize(doc))]) \n",
    "                for doc in document] \n",
    "    \n",
    "    \n",
    "    # Handle numbers: i.e. moneymoney used instead of <money> since will tokenize away the pointy brackets\n",
    "    # Duplication of term will be used an \"unique\" term\n",
    "    document = [re.sub(r'\\$ +[0-9]+(.[0-9]+)?', 'moneymoney', doc) for doc in document]\n",
    "    document = [re.sub(r'dollars?', 'moneymoney', doc) for doc in document]\n",
    "\n",
    "    document = [re.sub(r'[0-9]+(.[0-9]+)? \\%', 'percentpercent', doc) for doc in document]\n",
    "    document = [re.sub(r'(\\w)+ (percentage)+', 'percentpercent', doc) for doc in document]\n",
    "    document = [re.sub(r'(\\w)+ (\\%|percent)+', 'percentpercent', doc) for doc in document]\n",
    "    document = [re.sub(r'((hundred thousands?)|hundreds?|thousands?|millions?|billions?|trillions?)',\n",
    "                            'numbernumber', doc) for doc in document]\n",
    "    \n",
    "\n",
    "#     print((document))\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'text': ['Tom to is this the loves this car 59%', '1000000 Joseph is playing amazingly', 'Krish is running great this MORNING!!!', 'John owes me $100']}  \n",
    "  \n",
    "# Create DataFrame  \n",
    "data = pd.DataFrame(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean'] = preprocess(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom to is this the loves this car 59%</td>\n",
       "      <td>tom love percentpercent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000 Joseph is playing amazingly</td>\n",
       "      <td>1000000 joseph play amazingli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Krish is running great this MORNING!!!</td>\n",
       "      <td>krish run great morn ! ! !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John owes me $100</td>\n",
       "      <td>john owe moneymoney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text                          clean\n",
       "0   Tom to is this the loves this car 59%        tom love percentpercent\n",
       "1     1000000 Joseph is playing amazingly  1000000 joseph play amazingli\n",
       "2  Krish is running great this MORNING!!!     krish run great morn ! ! !\n",
       "3                       John owes me $100            john owe moneymoney"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['clean'] = preprocess(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "      <td>littl less decad ago , hockey fan bless slate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "      <td>writer hbo seri soprano took anoth dare storyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "      <td>despit claim tv news outlet offer 'nonstop new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "      <td>receiv 'subpar ' servic experienc unusu long w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "      <td>watch belov seattl marin prevail san diego pad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1  \\\n",
       "0  1  A little less than a decade ago, hockey fans w...   \n",
       "1  1  The writers of the HBO series The Sopranos too...   \n",
       "2  1  Despite claims from the TV news outlet to offe...   \n",
       "3  1  After receiving 'subpar' service and experienc...   \n",
       "4  1  After watching his beloved Seattle Mariners pr...   \n",
       "\n",
       "                                               clean  \n",
       "0  littl less decad ago , hockey fan bless slate ...  \n",
       "1  writer hbo seri soprano took anoth dare storyt...  \n",
       "2  despit claim tv news outlet offer 'nonstop new...  \n",
       "3  receiv 'subpar ' servic experienc unusu long w...  \n",
       "4  watch belov seattl marin prevail san diego pad...  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dataset/prep.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
